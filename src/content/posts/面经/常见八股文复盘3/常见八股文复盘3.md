---
title: 常见八股文复盘3
published: 2025-12-24
description: ''
image: '../cover.png'
tags: ["面经"]
category: '面经'
draft: false 
lang: ''
---




# （牛客）南京清能Java后端实习面经解答（通用八股文篇）


## 微服务相关
### 1. 讲一下你对微服务的了解
微服务是一种**架构设计风格**，核心是将传统的单体应用拆分为多个责任单一的服务，每个服务聚焦单一业务领域（如用户服务、支付服务），通过轻量级通信协议（HTTP/REST、gRPC）实现服务间协作，实现服务之前的解耦 。其核心特征包括：
- **单一职责**：每个服务仅负责一个业务模块，边界清晰。
- **独立部署**：服务可单独编译、打包、部署，修改某一服务不会影响其他服务。
- **技术异构**：不同服务可根据业务需求选择不同技术栈（如Java、Python、Go）。
- **去中心化**：无统一的中央控制节点，服务注册与发现、配置管理均为分布式架构。
- **弹性伸缩**：可针对单个服务进行水平扩展，应对不同服务的流量压力。

微服务架构的核心组件包含：服务注册与发现（Nacos/Eureka）、配置中心（Nacos/Apollo）、API网关（Spring Cloud Gateway/Gateway）、分布式事务（Seata）、服务熔断与限流（Sentinel/Hystrix）等。

### 2. Nacos它服务拉取，会拉哪些参数？
服务消费者从Nacos服务端拉取服务实例信息时，获取的是服务实例的**元数据集合**，核心参数可分为基础标识、网络信息、状态配置和自定义扩展四类，具体如下：
- **基础标识参数**：`serviceName`（服务名称，如`user-service`）、`groupName`（服务分组，用于业务归类）、`namespaceId`（命名空间ID，实现环境隔离，如开发/测试/生产环境）、`instanceId`（实例唯一标识）。
- **网络连接参数**：`ip`（服务实例的IP地址）、`port`（服务监听端口），这是服务调用的核心参数。
- **状态与配置参数**：`healthy`（实例健康状态）、`enabled`（实例是否启用）、`ephemeral`（是否为临时实例）、`weight`（实例权重，用于负载均衡）。
- **自定义元数据**：`metadata`（键值对形式，如`version=1.0`、`cluster=nj`，可用于灰度发布、集群路由等自定义逻辑）。

### 3. Nacos怎么保证一个服务没有宕机？
Nacos默认仅通过**客户端主动心跳上报**机制检测服务实例可用性，**服务端主动健康检查并非默认开启**，需手动配置。整体可用性检测分为客户端心跳上报和服务端健康检查两部分，核心流程如下：
1. **客户端心跳上报（默认开启）**
    - Nacos Client（服务实例）会以**5秒**为固定间隔，向Nacos Server发送心跳包（包含实例IP、端口、健康状态等信息），主动告知自身存活状态。
    - Nacos Server维护一个**心跳超时计数器**，若某实例的心跳包超时未达，会逐步修改其健康状态。

2. **服务端主动健康检查（需手动配置）**
    - 若需开启服务端主动检测，需在Nacos配置文件中设置健康检查类型（如`TCP`、`HTTP`）、检查间隔和超时时间。
    - Nacos Server会根据配置，定期向服务实例发送TCP连接请求或HTTP请求，若检测失败则标记实例为不健康。

3. **健康状态流转**
    - 若Nacos Server**15秒内未收到实例心跳**（或主动检测失败），会将实例的`healthy`状态置为`false`，此时实例仍在服务列表中，但不会被消费者选中。
    - 若**30秒内仍无心跳或检测持续失败**，临时实例会被从服务列表中移除，持久化实例仅标记为不健康，不会被移除。

### 4. 心跳机制的服务移除，是马上移除吗？
**不是立即移除**，Nacos针对心跳超时的实例采用**分级超时处理机制**，根据实例类型（临时/持久化）的不同，移除逻辑也存在差异，具体分为三个阶段：
1. **健康状态标记阶段（15秒超时）**
   客户端心跳间隔为5秒，若Nacos Server连续3个心跳周期（15秒）未收到实例心跳，会将实例的健康状态标记为**不健康（healthy=false）**。此时实例仍保留在服务列表中，只是消费端的负载均衡策略会跳过该实例。

2. **临时实例移除阶段（30秒超时）**
   若超时达到30秒仍未收到心跳，对于**临时实例（ephemeral=true，默认类型）**，Nacos Server会将其从服务列表中**逻辑移除**（并非物理删除，恢复心跳后可重新加入）。

3. **持久化实例保留阶段**
   对于**持久化实例（ephemeral=false，手动注册）**，即使心跳超时，Nacos Server也不会将其从服务列表中移除，仅持续标记为不健康，直到实例恢复心跳或手动删除。

### 5. 二阶段提交讲一下
二阶段提交（2PC）是分布式事务的经典解决方案，旨在保证分布式系统中多个节点的事务一致性，将事务执行分为**准备阶段**和**提交阶段**，由**协调者（Transaction Manager）** 和**参与者（Resource Manager）** 协同完成，核心流程如下：

#### （1）准备阶段（Prepare）
- 协调者向所有参与者发送**事务准备请求**，并携带事务上下文信息。
- 参与者接收到请求后，执行本地事务操作（如数据库SQL执行、资源锁定），但**不提交事务**，仅将操作结果（成功/失败）和事务日志记录反馈给协调者。
- 若参与者执行失败，直接向协调者返回失败结果；若执行成功，保持事务资源锁定状态，等待协调者的最终指令。

#### （2）提交阶段（Commit）
该阶段的执行逻辑取决于所有参与者的反馈结果，分为两种情况：
- **全量成功**：若所有参与者均返回执行成功，协调者向所有参与者发送**提交事务请求**。参与者接收到请求后，执行本地事务提交，释放锁定的资源，并向协调者返回提交成功结果。
- **任意失败**：若有任意一个参与者返回执行失败，协调者向所有参与者发送**回滚事务请求**。参与者根据事务日志执行本地事务回滚，释放资源，并向协调者返回回滚成功结果。

**二阶段提交的缺点**：存在同步阻塞问题（参与者需等待协调者指令，期间资源被锁定）、协调者单点故障风险、数据不一致问题（提交阶段网络异常可能导致部分参与者未执行提交）。

### 6. Seata的全局事务注解是什么？
Seata作为分布式事务框架，核心通过注解标记全局事务和本地事务，其中**`@GlobalTransactional`**是开启全局事务的核心注解，`@Transactional`用于标记本地事务参与者，具体说明如下：

1. **`@GlobalTransactional`**
    - 作用：标记在**全局事务发起方**的方法上，标识该方法为分布式事务的入口，Seata会自动创建全局事务ID并管理事务生命周期。
    - 常用属性：
        - `name`：事务名称，用于标识不同的全局事务。
        - `timeout`：全局事务超时时间，默认60秒，超时后事务会自动回滚。
        - `rollbackFor`：指定触发事务回滚的异常类型，如`rollbackFor = Exception.class`。
    - 示例：
   ```java
   @Service
   public class OrderService {
       @GlobalTransactional(name = "create-order-transaction", rollbackFor = Exception.class)
       public void createOrder() {
           // 调用本地订单服务
           // 远程调用库存服务、支付服务
       }
   }
   ```

2. **`@Transactional`**
    - 作用：标记在**参与者服务**的本地方法上，用于管理本地事务，与Seata全局事务协同，实现本地事务的提交或回滚。
    - 示例：
   ```java
   @Service
   public class StockService {
       @Transactional
       public void deductStock(Long productId) {
           // 本地库存扣减逻辑
       }
   }
   ```

Seata支持的事务模式包括AT（自动事务，默认）、TCC（手动事务）、SAGA（长事务）、XA（基于2PC），其中`@GlobalTransactional`注解适用于所有模式。

### 7. 有状态和无状态讲一下
在分布式系统中，**有状态**和**无状态**是针对服务实例是否存储业务上下文数据的划分，直接影响服务的扩展性和可用性，具体定义与特点如下：

- **无状态服务**
  服务实例不存储任何业务相关的上下文数据，每次请求的处理仅依赖请求参数和外部存储（如数据库），所有实例完全等价。
    - 示例：用户查询服务，每次查询都从数据库读取用户信息，服务本身不缓存数据。
    - 优势：可无限水平扩展，实例宕机不会丢失数据，请求可随机转发到任意实例。
    - 微服务架构中推荐设计为无状态服务，状态数据统一存储在分布式数据库或缓存中。

- **有状态服务**
  服务实例会存储业务上下文数据（如用户会话、请求状态），后续请求的处理依赖实例本地存储的数据。
    - 示例：传统的Session服务，用户登录状态保存在服务实例的本地Session中。
    - 缺点：扩展困难，需通过会话粘滞（如Nginx的ip_hash）将用户请求固定到特定实例，实例宕机会导致数据丢失。

### 8. 如果有一个用户，消息接收失败了，应该怎么办？
用户消息接收失败是分布式系统中的常见问题，需根据失败原因（网络抖动、服务异常、用户端问题）采取分层处理策略，核心解决方案如下：
1. **瞬时故障重试**
   对于网络抖动、服务临时不可用等瞬时故障，采用**有限次数的重试机制**，并使用**指数退避策略**（如重试间隔1s、2s、4s），避免频繁重试加剧服务压力。重试次数一般设置为3次，超过则进入失败处理流程。

2. **消息持久化与重发**
   将发送失败的消息持久化到数据库或消息队列中，保证消息不丢失。通过**定时任务**扫描持久化的失败消息，在服务恢复后自动重发；对于重要消息（如业务通知），提供手动重发的入口。

3. **死信队列隔离与分析**
   若使用消息队列发送消息，将多次重试失败的消息转入**死信队列**，避免无效消息堆积影响正常消息消费。由专门的监控和处理模块分析死信消息的失败原因（如用户地址错误、服务长期不可用），并针对性解决。

4. **用户端补偿通知**
   通过短信、邮件、APP推送等备用渠道通知用户消息发送失败，并说明失败原因和解决方式；对于核心业务消息，安排人工介入核实并补发。

5. **服务降级与熔断**
   若消息接收方服务持续异常，暂时熔断对该服务的消息发送，将消息暂存到临时队列，待服务恢复后再恢复发送，避免消息队列阻塞。

## Java基础&Spring相关
### 1. Spring的bean是怎么注入的？
Spring中Bean的注入本质是将依赖对象赋值给目标Bean的过程，核心分为**构造器注入**、**Setter方法注入**、**字段注入**三类，同时支持`@Resource`、`@Qualifier`等注解辅助注入，具体如下：

#### （1）构造器注入（Spring官方推荐）
通过构造方法传入依赖对象，保证Bean初始化时依赖已完全注入，且依赖对象不可变。适用于强制依赖的场景。
```java
@Service
public class OrderService {
    private final UserService userService;

    // 构造器注入，Spring自动匹配依赖
    public OrderService(UserService userService) {
        this.userService = userService;
    }
}
```

#### （2）Setter方法注入
通过Setter方法注入依赖，适用于可选依赖的场景，可在运行时动态修改依赖对象。
```java
@Service
public class OrderService {
    private UserService userService;

    @Autowired // 标记Setter方法为注入点
    public void setUserService(UserService userService) {
        this.userService = userService;
    }
}
```

#### （3）字段注入（简化写法）
直接在字段上标注`@Autowired`，由Spring通过反射直接注入依赖，无需编写构造器或Setter方法。缺点是无法实现依赖不可变，且不利于单元测试。
```java
@Service
public class OrderService {
    @Autowired // 字段注入
    private UserService userService;
}
```

#### （4）其他注入注解
- `@Resource`：JDK提供的注解，默认按**名称**注入，名称不存在时按类型注入；可通过`name`属性指定注入的Bean名称。
- `@Qualifier`：配合`@Autowired`使用，解决同类型多个Bean的注入冲突，指定具体的Bean名称。
  ```java
  @Autowired
  @Qualifier("userServiceImpl") // 指定注入名为userServiceImpl的Bean
  private UserService userService;
  ```

### 2. AOP了解过吗？
AOP（面向切面编程）是Spring的核心特性之一，旨在将**横切关注点**（如日志记录、事务管理、权限校验）从业务逻辑中抽离，实现代码复用和业务逻辑的解耦。

#### （1）AOP核心概念
- **切面（Aspect）**：封装横切逻辑的类，如`LogAspect`、`TransactionAspect`。
- **连接点（JoinPoint）**：程序执行过程中的任意节点，如方法调用、异常抛出。
- **切入点（Pointcut）**：匹配连接点的规则，指定切面作用的具体位置（如某个包下的所有方法）。
- **通知（Advice）**：切面的具体执行逻辑，分为五种类型：
    - `@Before`：目标方法执行前执行。
    - `@After`：目标方法执行后执行（无论是否抛出异常）。
    - `@AfterReturning`：目标方法正常返回后执行。
    - `@AfterThrowing`：目标方法抛出异常后执行。
    - `@Around`：环绕通知，可控制目标方法的执行时机和流程，是功能最强大的通知类型。

#### （2）AOP实现示例（日志切面）
```java
@Aspect // 标记为切面类
@Component // 交由Spring容器管理
public class LogAspect {
    // 定义切入点：匹配com.service包下所有类的所有方法
    @Pointcut("execution(* com.service.*.*(..))")
    public void servicePointcut() {}

    // 环绕通知
    @Around("servicePointcut()")
    public Object logAround(ProceedingJoinPoint joinPoint) throws Throwable {
        // 方法执行前：记录请求信息
        String methodName = joinPoint.getSignature().getName();
        System.out.println("方法" + methodName + "开始执行");
        long startTime = System.currentTimeMillis();

        // 执行目标方法
        Object result = joinPoint.proceed();

        // 方法执行后：记录耗时
        long endTime = System.currentTimeMillis();
        System.out.println("方法" + methodName + "执行结束，耗时：" + (endTime - startTime) + "ms");
        return result;
    }
}
```

### 3. HashMap和ConcurrentHashMap有什么区别？
HashMap和ConcurrentHashMap均为Java中的Map实现，但在**线程安全**、**锁机制**、**功能支持**等方面存在显著差异，具体对比如下：

| 特性                | HashMap                          | ConcurrentHashMap                |
|---------------------|----------------------------------|----------------------------------|
| **线程安全**        | 非线程安全，多线程环境下可能出现数据竞争、死循环等问题 | 线程安全，专为高并发场景设计      |
| **锁机制**          | 无锁实现                         | JDK 1.7：采用**分段锁（Segment）**，将哈希表分为多个段，每个段独立加锁；JDK 1.8：摒弃分段锁，采用**CAS + 同步锁（Synchronized）**，仅对哈希桶加锁，锁粒度更细 |
| **null值支持**      | 允许key和value为null（key仅允许一个null） | 不允许key或value为null，避免并发场景下null值无法区分“键不存在”和“值为null” |
| **扩容机制**        | 单线程扩容，扩容期间哈希表不可访问 | 多线程协助扩容，扩容期间哈希表仍可正常读写 |
| **迭代器特性**      | 快速失败（Fast-Fail），迭代过程中若修改Map会抛出ConcurrentModificationException | 弱一致性迭代器，迭代过程中允许修改Map，不会抛出异常 |
| **性能**            | 无锁开销，单线程下性能优异       | 高并发下性能远优于Hashtable，低并发下略低于HashMap |

### 4. map的key可以设置为空值吗？
不同Map实现对`null`key的支持由其底层实现逻辑决定，核心实现类的支持情况如下：
- **HashMap**：允许**一个**`null`key。因为HashMap通过`hashCode()`计算key的哈希值，`null`key的哈希值被固定为0，会被存储在哈希表的0号桶中，且仅能存在一个`null`key。同时允许value为null。
- **ConcurrentHashMap**：不允许`null`key和`null`value。在并发场景下，`null`值无法区分“键不存在”和“值为null”，容易导致业务逻辑错误，因此底层会直接抛出`NullPointerException`。
- **TreeMap**：不允许`null`key。TreeMap基于红黑树实现，需要对key进行排序（实现`Comparable`接口或自定义Comparator），而`null`无法调用`compareTo()`方法，会抛出`NullPointerException`；但允许value为null。
- **Hashtable**：不允许`null`key和`null`value。作为早期的线程安全Map实现，底层对`null`值做了严格校验，传入`null`会直接抛出异常。

### 5. AQS有了解吗？里面有哪些锁？
AQS（AbstractQueuedSynchronizer）是Java并发包（`java.util.concurrent`）的核心框架，为锁和同步工具提供底层的同步机制支持，基于**CLH队列**和**volatile状态位**实现线程的排队与唤醒。

#### （1）AQS核心原理
- **状态管理**：通过`volatile int state`变量存储同步状态（如重入锁的重入次数、信号量的许可数），并通过CAS操作保证状态修改的原子性。
- **等待队列**：当线程获取同步状态失败时，会被封装为`Node`节点加入CLH双向队列，等待前驱节点释放锁后被唤醒。
- **条件队列**：支持`Condition`接口，线程可通过`await()`进入条件队列等待，通过`signal()`被唤醒并转移到等待队列。

#### （2）基于AQS实现的锁与同步工具
AQS是基础框架，Java并发包中的多数锁和同步工具均基于其实现，核心包括：
- **ReentrantLock（重入锁）**：可重入的独占锁，支持公平锁和非公平锁。
- **ReentrantReadWriteLock（读写锁）**：读锁为共享锁，写锁为独占锁，适用于读多写少的场景。
- **Semaphore（信号量）**：控制同时访问资源的线程数量，基于共享锁实现。
- **CountDownLatch（倒计时门闩）**：让一组线程等待其他线程完成操作后再执行，基于共享锁实现。
- **CyclicBarrier（循环屏障）**：让一组线程相互等待，直到所有线程到达屏障点后继续执行，底层依赖ReentrantLock和Condition。
- **FutureTask**：实现异步任务的结果获取，基于AQS的同步状态管理任务执行状态。

### 6. 讲一下重入锁吧
重入锁（`ReentrantLock`）是基于AQS实现的**独占锁**，核心特性是**可重入性**，即同一线程可多次获取同一把锁，而不会产生死锁。其核心特点与使用方式如下：

1. **可重入性**
   当线程获取锁后，再次调用`lock()`方法时会直接成功，锁的同步状态`state`会递增（记录重入次数）；释放锁时调用`unlock()`，`state`递减，直到`state`为0时才真正释放锁。
   ```java
   ReentrantLock lock = new ReentrantLock();
   public void method1() {
       lock.lock(); // state=1
       try {
           method2();
       } finally {
           lock.unlock(); // state=0，释放锁
       }
   }
   public void method2() {
       lock.lock(); // state=2，重入成功
       try {
           // 业务逻辑
       } finally {
           lock.unlock(); // state=1
       }
   }
   ```

2. **公平锁与非公平锁**
    - **非公平锁（默认）**：线程获取锁时直接尝试CAS修改状态，若失败则加入等待队列，性能更高（减少线程切换）。
    - **公平锁**：线程按等待队列的顺序获取锁，不会出现插队现象，保证公平性但性能较低。创建公平锁需指定构造参数：`ReentrantLock lock = new ReentrantLock(true);`。

3. **可中断锁**
   支持`lockInterruptibly()`方法，线程在等待获取锁的过程中可被中断（调用`thread.interrupt()`），避免线程无限期等待锁导致死锁。

4. **条件变量（Condition）**
   通过`newCondition()`方法创建Condition对象，实现线程的精准等待与唤醒，支持多个条件队列，比Object的`wait()`/`notify()`更灵活。

### 7. 线程池了解过吗？有哪些参数？
线程池是管理线程生命周期的工具，旨在减少线程创建与销毁的开销，提高并发程序的性能。`ThreadPoolExecutor`是Java中线程池的核心实现类，其构造方法包含**7个核心参数**，每个参数决定了线程池的运行机制，具体如下：
```java
public ThreadPoolExecutor(int corePoolSize,
                          int maximumPoolSize,
                          long keepAliveTime,
                          TimeUnit unit,
                          BlockingQueue<Runnable> workQueue,
                          ThreadFactory threadFactory,
                          RejectedExecutionHandler handler)
```

1. **corePoolSize（核心线程数）**
   线程池长期保持的线程数量，即使线程处于空闲状态也不会被销毁（除非设置`allowCoreThreadTimeOut(true)`）。当任务数小于核心线程数时，直接创建新线程执行任务。

2. **maximumPoolSize（最大线程数）**
   线程池允许创建的最大线程数，限制了线程池的并发能力。当任务队列满且核心线程数已用完时，会创建非核心线程执行任务，直到线程数达到该值。

3. **keepAliveTime（非核心线程空闲超时时间）**
   非核心线程处于空闲状态的最长存活时间，超过该时间则被销毁，释放资源。

4. **unit（时间单位）**
   `keepAliveTime`的时间单位，如`TimeUnit.SECONDS`、`TimeUnit.MILLISECONDS`。

5. **workQueue（任务队列）**
   用于存储等待执行的任务的阻塞队列，常见实现有：
    - `ArrayBlockingQueue`：有界数组队列，需指定容量。
    - `LinkedBlockingQueue`：无界链表队列（默认），可导致线程池达到核心线程数后不再创建新线程。
    - `SynchronousQueue`：同步队列，不存储任务，直接将任务传递给线程。

6. **threadFactory（线程工厂）**
   用于创建线程的工厂，可自定义线程的名称、优先级、是否为守护线程等。

7. **handler（拒绝策略）**
   当任务队列满且线程数达到最大时，处理新任务的策略，JDK默认提供四种：
    - `AbortPolicy`：抛出`RejectedExecutionException`（默认）。
    - `CallerRunsPolicy`：由调用者线程执行任务。
    - `DiscardPolicy`：直接丢弃新任务。
    - `DiscardOldestPolicy`：丢弃队列中最旧的任务，执行新任务。

### 8. 我有三个异步的线程，怎么把他们同步在一条水平线上？
要让三个异步线程**全部执行完成后再继续后续操作**，即实现线程的同步等待，核心可通过`CountDownLatch`、`CyclicBarrier`、`CompletableFuture`三种方式实现，具体如下：

#### （1）使用`CountDownLatch`（倒计时门闩）
通过计数器实现主线程等待子线程执行完成，计数器初始值为线程数，每个线程执行完后将计数器减1，计数器为0时主线程继续执行。
```java
public class ThreadSyncDemo {
    public static void main(String[] args) throws InterruptedException {
        CountDownLatch latch = new CountDownLatch(3); // 计数器初始值3

        // 线程1
        new Thread(() -> {
            try {
                Thread.sleep(1000);
                System.out.println("线程1执行完成");
            } catch (InterruptedException e) {
                e.printStackTrace();
            } finally {
                latch.countDown(); // 计数器减1
            }
        }).start();

        // 线程2
        new Thread(() -> {
            try {
                Thread.sleep(2000);
                System.out.println("线程2执行完成");
            } catch (InterruptedException e) {
                e.printStackTrace();
            } finally {
                latch.countDown();
            }
        }).start();

        // 线程3
        new Thread(() -> {
            try {
                Thread.sleep(1500);
                System.out.println("线程3执行完成");
            } catch (InterruptedException e) {
                e.printStackTrace();
            } finally {
                latch.countDown();
            }
        }).start();

        latch.await(); // 主线程等待，直到计数器为0
        System.out.println("所有线程执行完成，继续后续操作");
    }
}
```

#### （2）使用`CyclicBarrier`（循环屏障）
让多个线程到达屏障点后再继续执行，可重复使用。当指定数量的线程到达屏障点后，执行屏障任务（如后续操作）。
```java
public class ThreadSyncDemo {
    public static void main(String[] args) {
        // 屏障点数量为3，到达后执行指定任务
        CyclicBarrier barrier = new CyclicBarrier(3, () -> {
            System.out.println("所有线程执行完成，继续后续操作");
        });

        // 线程1
        new Thread(() -> {
            try {
                Thread.sleep(1000);
                System.out.println("线程1执行完成");
                barrier.await(); // 到达屏障点
            } catch (Exception e) {
                e.printStackTrace();
            }
        }).start();

        // 线程2、线程3实现逻辑与线程1一致，此处省略
    }
}
```

#### （3）使用`CompletableFuture`（Java 8+）
基于异步编程模型，通过`allOf()`方法等待所有异步任务执行完成，适用于Java 8及以上版本。
```java
public class ThreadSyncDemo {
    public static void main(String[] args) throws Exception {
        // 创建三个异步任务
        CompletableFuture<Void> task1 = CompletableFuture.runAsync(() -> {
            try {
                Thread.sleep(1000);
                System.out.println("线程1执行完成");
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        });

        CompletableFuture<Void> task2 = CompletableFuture.runAsync(() -> {
            try {
                Thread.sleep(2000);
                System.out.println("线程2执行完成");
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        });

        CompletableFuture<Void> task3 = CompletableFuture.runAsync(() -> {
            try {
                Thread.sleep(1500);
                System.out.println("线程3执行完成");
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        });

        // 等待所有任务完成
        CompletableFuture.allOf(task1, task2, task3).get();
        System.out.println("所有线程执行完成，继续后续操作");
    }
}
```

### 9. 讲一下CAS的思想
CAS（Compare And Swap，比较并交换）是**乐观锁**的核心实现机制，旨在无锁情况下保证多线程对共享变量操作的原子性，广泛应用于Java并发包的底层实现。

#### （1）CAS核心思想
CAS操作包含三个核心参数：**内存地址（V）**、**预期值（A）**、**新值（B）**。其操作逻辑为：
1. 读取内存地址`V`中的当前值，与预期值`A`进行比较。
2. 若两者相等，说明该值未被其他线程修改，将内存地址`V`的值更新为新值`B`，返回操作成功。
3. 若两者不相等，说明该值已被其他线程修改，放弃更新并返回操作失败。
4. 操作失败后，可通过**自旋**（循环重试）再次执行CAS操作，直到成功或达到重试次数上限。

#### （2）CAS的Java实现
Java中通过`sun.misc.Unsafe`类提供CAS的底层实现，`AtomicInteger`、`AtomicLong`等原子类均基于CAS实现。示例如下：
```java
import java.util.concurrent.atomic.AtomicInteger;

public class CASDemo {
    public static void main(String[] args) {
        AtomicInteger atomicInt = new AtomicInteger(0);
        // CAS操作：预期值为0，新值为1
        boolean success = atomicInt.compareAndSet(0, 1);
        System.out.println(success); // true，atomicInt的值变为1

        // 再次执行CAS：预期值为0，实际值为1，操作失败
        success = atomicInt.compareAndSet(0, 2);
        System.out.println(success); // false，atomicInt的值仍为1
    }
}
```

#### （3）CAS的问题与解决方案
- **ABA问题**：线程1读取值为A，线程2将A改为B后又改回A，线程1的CAS操作会误认为值未被修改。解决方案：使用`AtomicStampedReference`为变量添加版本号，通过版本号判断值是否被修改。
- **自旋开销**：若CAS频繁失败，线程会一直自旋重试，消耗CPU资源。解决方案：限制自旋次数，或在自旋次数达到阈值后切换为阻塞锁。
- **单变量原子性**：CAS仅能保证单个变量操作的原子性，无法实现多个变量的原子操作。解决方案：将多个变量封装为对象，使用`AtomicReference`保证对象引用的原子性。

## 其他通用问题
### 1. 你为什么要用ThreadLocal？
`ThreadLocal`是Java提供的**线程本地存储**工具，为每个线程创建独立的变量副本，使线程之间的变量相互隔离，核心使用场景与原因如下：

1. **保存线程上下文信息**
   在业务流程中，将用户登录信息、请求ID、数据库连接等上下文数据存储在`ThreadLocal`中，可在线程的任意方法中获取，无需通过方法参数传递，简化代码逻辑。
   ```java
   // 存储用户信息的ThreadLocal
   private static final ThreadLocal<User> userThreadLocal = new ThreadLocal<>();

   // 设置用户信息
   public static void setCurrentUser(User user) {
       userThreadLocal.set(user);
   }

   // 获取当前线程的用户信息
   public static User getCurrentUser() {
       return userThreadLocal.get();
   }
   ```

2. **避免线程安全问题**
   对于非线程安全的对象（如`SimpleDateFormat`、`Random`），每个线程通过`ThreadLocal`持有独立的对象副本，避免多线程共享导致的并发问题，且无需加锁，性能优于同步机制。

3. **数据库连接与事务管理**
   在数据库操作中，为每个线程分配独立的数据库连接，通过`ThreadLocal`存储，保证事务的隔离性（同一线程的所有数据库操作使用同一个连接）。

**注意**：使用`ThreadLocal`后需调用`remove()`方法清理变量，尤其是在线程池环境中，线程复用会导致变量副本长期存在，引发内存泄漏。

### 2. 我创建了一个异步的线程，那ThreadLocal里的数据怎么办？
`ThreadLocal`的变量副本与线程绑定，异步线程无法直接获取主线程`ThreadLocal`中的数据，需通过手动传递、继承性扩展或专用工具解决，核心方案如下：

1. **手动传递数据**
   将主线程`ThreadLocal`中的数据取出，作为参数传递给异步线程，这是最基础且可靠的方式。
   ```java
   // 主线程中获取ThreadLocal数据
   User user = userThreadLocal.get();

   // 异步线程接收数据并使用
   new Thread(() -> {
       System.out.println("异步线程获取的用户信息：" + user.getName());
   }).start();
   ```

2. **使用`InheritableThreadLocal`**
   `InheritableThreadLocal`是`ThreadLocal`的子类，支持**父子线程的数据继承**，子线程会自动复制父线程`InheritableThreadLocal`中的变量副本。
   ```java
   // 替换为InheritableThreadLocal
   private static final ThreadLocal<User> userThreadLocal = new InheritableThreadLocal<>();

   // 主线程设置数据
   userThreadLocal.set(new User("admin"));

   // 异步线程（子线程）可直接获取数据
   new Thread(() -> {
       User user = userThreadLocal.get(); // 获取到admin
       System.out.println(user.getName());
   }).start();
   ```
   **局限性**：仅支持父子线程的继承，线程池中的线程是复用的，并非主线程的子线程，因此无法继承数据。

3. **使用TransmittableThreadLocal（TTL）**
   阿里开源的`TransmittableThreadLocal`解决了线程池环境下`ThreadLocal`数据传递的问题，通过封装线程池，实现任务提交时的`ThreadLocal`数据拷贝与恢复，适用于微服务、分布式追踪等场景。

### 3. 分布式锁和CAS你是怎么用的？
#### （1）分布式锁的使用场景与实现
**使用场景**：分布式系统中保证跨服务、跨节点的资源互斥访问（如共享资源操作、业务流程的串行化执行）。
**基于数据库行锁的分布式锁实现**（适用于中小型项目）：
```java
// 获取分布式锁：通过数据库行锁实现
public boolean tryLock(Long resourceId) {
    try (Connection conn = getConnection()) {
        // 开启事务
        conn.setAutoCommit(false);
        // 对资源记录加行锁（for update）
        String sql = "SELECT id FROM resource_lock WHERE resource_id = ? FOR UPDATE";
        PreparedStatement pstmt = conn.prepareStatement(sql);
        pstmt.setLong(1, resourceId);
        ResultSet rs = pstmt.executeQuery();
        // 若存在该资源记录则获取锁成功
        boolean locked = rs.next();
        conn.commit();
        return locked;
    } catch (Exception e) {
        e.printStackTrace();
        return false;
    }
}

// 释放锁：事务提交后自动释放行锁
public void releaseLock() {
    // 无需额外操作，事务提交后行锁自动释放
}

// 业务中使用分布式锁
public void operateResource(Long resourceId) {
    try {
        boolean locked = tryLock(resourceId);
        if (!locked) {
            throw new RuntimeException("资源正被占用，请稍后再试");
        }
        // 共享资源的业务操作
    } finally {
        releaseLock();
    }
}
```

#### （2）CAS的使用场景与实现
**使用场景**：单进程内的原子操作（如计数器、状态更新），避免加锁带来的性能开销。
**基于`AtomicInteger`的CAS实现计数器**：
```java
public class Counter {
    // 基于CAS的原子整数
    private final AtomicInteger count = new AtomicInteger(0);

    // 原子递增
    public int increment() {
        return count.incrementAndGet();
    }

    // 原子递减
    public int decrement() {
        return count.decrementAndGet();
    }

    // 获取当前计数
    public int getCount() {
        return count.get();
    }
}
```

**自定义CAS操作**（基于`Unsafe`类）：
```java
public class CustomCAS {
    private volatile int value; // 共享变量
    private static final Unsafe unsafe;
    private static final long valueOffset; // 变量的内存地址偏移量

    // 静态代码块初始化Unsafe与偏移量
    static {
        try {
            unsafe = Unsafe.getUnsafe();
            valueOffset = unsafe.objectFieldOffset(CustomCAS.class.getDeclaredField("value"));
        } catch (Exception e) {
            throw new Error(e);
        }
    }

    public CustomCAS(int value) {
        this.value = value;
    }

    // CAS操作核心方法
    public boolean compareAndSet(int expect, int update) {
        return unsafe.compareAndSwapInt(this, valueOffset, expect, update);
    }

    public int getValue() {
        return value;
    }
}
```

### 4. 你用的什么数据库？
（实习岗可结合项目实际情况回答，以下为通用示例）
在项目开发中，主要使用**MySQL**作为关系型数据库，原因是MySQL开源免费、社区生态成熟，与Java开发生态兼容性好，且对中小型项目的并发和数据量支持足够。同时，也了解**PostgreSQL**的基础特性，它在复杂查询、数据类型支持（如JSON、地理空间数据）上更具优势，适用于数据结构复杂的场景。

针对MySQL的使用，做了基础的性能优化：如合理设计主键和索引（避免冗余索引）、使用分页查询减少数据加载量、针对读多写少的场景做了读写分离的初步尝试，提升了数据库的并发处理能力。

### 5. 索引分类有哪些？
数据库索引是提升查询效率的核心，MySQL中索引可按**存储结构**、**逻辑功能**、**索引列数量**等维度分类，具体如下：

1. **按存储结构分类**
    - **B+树索引**：MySQL默认的索引类型，所有数据存储在叶子节点，叶子节点形成双向链表，支持范围查询和排序，适用于主键索引、普通索引、组合索引。
    - **哈希索引**：基于哈希表实现，查询单条数据速度快，但不支持范围查询和排序，仅Memory存储引擎默认使用。
    - **全文索引**：用于文本内容的全文检索（如`FULLTEXT`索引），适用于`CHAR`、`VARCHAR`、`TEXT`类型的列。
    - **R树索引**：针对地理空间数据类型（如`GEOMETRY`）设计，支持空间范围查询。

2. **按逻辑功能分类**
    - **主键索引（PRIMARY KEY）**：唯一标识表中的记录，不允许为空，一张表仅能有一个主键索引，默认采用B+树结构。
    - **唯一索引（UNIQUE）**：保证索引列的值唯一，允许存在一个`NULL`值，可用于防止数据重复。
    - **普通索引（INDEX）**：最基础的索引类型，无唯一性限制，仅用于加速查询。
    - **空间索引（SPATIAL）**：用于地理空间数据的索引，仅支持MyISAM和InnoDB（MySQL 5.7+）存储引擎。

3. **按索引列数量分类**
    - **单列索引**：仅包含单个列的索引，如`INDEX idx_name (name)`。
    - **复合索引（组合索引）**：由多个列组成的索引，遵循**最左前缀原则**，如`INDEX idx_name_age (name, age)`。

### 6. 死信队列是什么？
死信队列（Dead-Letter Queue，DLQ）是消息队列的**特殊附属队列**，用于存储无法被正常消费的消息（死信消息）。当消息满足特定条件时，会被从正常队列转移到死信队列，核心定义与特性如下：

1. **死信消息的产生条件**
    - **消息过期**：消息设置了过期时间（TTL），超时后仍未被消费。
    - **队列满员**：消息队列达到最大容量，无法接收新消息，导致旧消息无法被消费。
    - **消费失败**：消息被消费端多次重试后仍消费失败（如抛出未捕获的异常）。

2. **死信队列的核心作用**
    - **隔离无效消息**：避免死信消息堆积在正常队列中，影响正常消息的消费速度和稳定性。
    - **故障排查**：通过分析死信消息的内容和失败原因，定位消费端的问题（如业务逻辑错误、消息格式异常）。
    - **消息重试与补偿**：可对死信队列中的消息进行二次处理（如人工干预后重新发送），保证消息的最终一致性。

3. **典型应用场景**
   死信队列常用于支付结果回调、订单状态通知、分布式事务消息等场景，是保证消息系统可靠性的重要组件。
